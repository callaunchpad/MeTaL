{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "\n",
    "#import system things\n",
    "# from tensorflow.examples.tutorials.mnist import input_data # for data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def visualize(embed, x_test, y_test):\n",
    "\n",
    "    # two ways of visualization: scale to fit [0,1] scale\n",
    "    # feat = embed - np.min(embed, 0)\n",
    "    # feat /= np.max(feat, 0)\n",
    "\n",
    "    # two ways of visualization: leave with original scale\n",
    "    feat = embed\n",
    "    ax_min = np.min(embed,0)\n",
    "    ax_max = np.max(embed,0)\n",
    "    ax_dist_sq = np.sum((ax_max-ax_min)**2)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    colormap = plt.get_cmap('tab10')\n",
    "    shown_images = np.array([[1., 1.]])\n",
    "    for i in range(feat.shape[0]):\n",
    "        dist = np.sum((feat[i] - shown_images)**2, 1)\n",
    "        if np.min(dist) < 3e-4*ax_dist_sq:   # don't show points that are too close\n",
    "            continue\n",
    "        shown_images = np.r_[shown_images, [feat[i]]]\n",
    "        patch_to_color = np.expand_dims(x_test[i], -1)\n",
    "        patch_to_color = np.tile(patch_to_color, (1, 1, 3))\n",
    "        patch_to_color = (1-patch_to_color) * (1,1,1) + patch_to_color * colormap(y_test[i]/10.)[:3]\n",
    "        imagebox = offsetbox.AnnotationBbox(\n",
    "            offsetbox.OffsetImage(patch_to_color, zoom=0.5, cmap=plt.cm.gray_r),\n",
    "            xy=feat[i], frameon=False\n",
    "        )\n",
    "        ax.add_artist(imagebox)\n",
    "\n",
    "    plt.axis([ax_min[0], ax_max[0], ax_min[1], ax_max[1]])\n",
    "    # plt.xticks([]), plt.yticks([])\n",
    "    plt.title('Embedding from the last layer of the network')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Siamese:\n",
    "\n",
    "    # Create model\n",
    "    def __init__(self):\n",
    "        self.x1 = tf.placeholder(tf.float32, [None, 784])\n",
    "        self.x2 = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "        with tf.variable_scope(\"siamese\", reuse=tf.AUTO_REUSE) as scope:\n",
    "            self.o1 = self.network(self.x1)\n",
    "            scope.reuse_variables()\n",
    "            self.o2 = self.network(self.x2)\n",
    "\n",
    "        # Create loss\n",
    "        self.y_ = tf.placeholder(tf.float32, [None])\n",
    "        self.loss = self.loss_with_spring()\n",
    "\n",
    "    def network(self, x):\n",
    "        weights = []\n",
    "        fc1 = self.fc_layer(x, 1024, \"fc1\")\n",
    "        ac1 = tf.nn.relu(fc1)\n",
    "        fc2 = self.fc_layer(ac1, 1024, \"fc2\")\n",
    "        ac2 = tf.nn.relu(fc2)\n",
    "        fc3 = self.fc_layer(ac2, 2, \"fc3\")\n",
    "        return fc3\n",
    "\n",
    "    def fc_layer(self, bottom, n_weight, name):\n",
    "        assert len(bottom.get_shape()) == 2\n",
    "        n_prev_weight = bottom.get_shape()[1]\n",
    "        initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "        W = tf.get_variable(name+'W', dtype=tf.float32, shape=[n_prev_weight, n_weight], initializer=initer)\n",
    "        b = tf.get_variable(name+'b', dtype=tf.float32, initializer=tf.constant(0.01, shape=[n_weight], dtype=tf.float32))\n",
    "        fc = tf.nn.bias_add(tf.matmul(bottom, W), b)\n",
    "        return fc\n",
    "\n",
    "    def loss_with_spring(self):\n",
    "        margin = 5.0\n",
    "        labels_t = self.y_\n",
    "        labels_f = tf.subtract(1.0, self.y_, name=\"1-yi\")          # labels_ = !labels;\n",
    "        eucd2 = tf.pow(tf.subtract(self.o1, self.o2), 2)\n",
    "        eucd2 = tf.reduce_sum(eucd2, 1)\n",
    "        eucd = tf.sqrt(eucd2+1e-6, name=\"eucd\")\n",
    "        C = tf.constant(margin, name=\"C\")\n",
    "        # yi*||CNN(p1i)-CNN(p2i)||^2 + (1-yi)*max(0, C-||CNN(p1i)-CNN(p2i)||^2)\n",
    "        pos = tf.multiply(labels_t, tf.pow(eucd,2), name=\"yi_x_eucd2\")\n",
    "#         neg = tf.multiply(labels_f, tf.subtract(0.0,eucd2), name=\"yi_x_eucd2\")\n",
    "#         neg = tf.multiply(labels_f, tf.maximum(0.0, tf.subtract(C,eucd2)), name=\"Nyi_x_C-eucd_xx_2\")\n",
    "        neg = tf.multiply(labels_f, tf.pow(tf.maximum(tf.subtract(C, eucd), 0.0), 2), name=\"Nyi_x_C-eucd_xx_2\")\n",
    "        losses = tf.add(pos, neg, name=\"losses\")\n",
    "        loss = tf.reduce_mean(losses, name=\"loss\")\n",
    "        return loss\n",
    "\n",
    "    def loss_with_step(self):\n",
    "        margin = 5.0\n",
    "        labels_t = self.y_\n",
    "        labels_f = tf.subtract(1.0, self.y_, name=\"1-yi\")          # labels_ = !labels;\n",
    "        eucd2 = tf.pow(tf.subtract(self.o1, self.o2), 2)\n",
    "        eucd2 = tf.reduce_sum(eucd2, 1)\n",
    "        eucd = tf.sqrt(eucd2+1e-6, name=\"eucd\")\n",
    "        C = tf.constant(margin, name=\"C\")\n",
    "        pos = tf.multiply(labels_t, eucd, name=\"y_x_eucd\")\n",
    "        neg = tf.multiply(labels_f, tf.maximum(0.0, tf.subtract(C, eucd)), name=\"Ny_C-eucd\")\n",
    "        losses = tf.add(pos, neg, name=\"losses\")\n",
    "        loss = tf.reduce_mean(losses, name=\"loss\")\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "batch_size = 128\n",
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "shuffle_in_unison(np.copy(train_images), np.copy(train_labels))\n",
    "shuffle_in_unison(np.copy(test_images), np.copy(test_labels))\n",
    "\n",
    "def get_train_mini_batch(iter_num):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        iter_num: iteration number\n",
    "    Returns:\n",
    "        Tuple of training images and labels\n",
    "    \"\"\"\n",
    "    start = (iter_num * batch_size)% train_images.shape[0]\n",
    "    end = min(start + batch_size, train_images.shape[0])\n",
    "    images = train_images[start:end]\n",
    "    images = images.reshape([images.shape[0], 784])\n",
    "    \n",
    "    labels = np.zeros([end-start, 10])\n",
    "    label_ints = train_labels[start:end].astype(int)\n",
    "#     labels[np.arange(end-start), label_ints] = 1\n",
    "    \n",
    "    return (images, label_ints)\n",
    "\n",
    "def get_test_mini_batch(iter_num):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        iter_num: iteration number\n",
    "    Returns:\n",
    "        Tuple of training images and labels\n",
    "    \"\"\"\n",
    "    start = (iter_num * batch_size)% test_images.shape[0]\n",
    "    end = min(start + batch_size, test_images.shape[0])\n",
    "    images = test_images[start:end]\n",
    "    images = images.reshape([images.shape[0], 784])\n",
    "    \n",
    "    labels = np.zeros([end-start, 10])\n",
    "    label_ints = test_labels[start:end].astype(int)\n",
    "    labels[np.arange(end-start), label_ints] = 1\n",
    "    \n",
    "    return (images, label_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found model files. Do you want to load it and continue training [yes/no]?no\n",
      "step 0: loss 15.868\n",
      "step 10: loss 3.340\n",
      "step 20: loss 2.820\n",
      "step 30: loss 3.512\n",
      "step 40: loss 2.216\n",
      "step 50: loss 1.545\n",
      "step 60: loss 2.737\n",
      "step 70: loss 2.227\n",
      "step 80: loss 2.552\n",
      "step 90: loss 3.018\n",
      "step 100: loss 2.118\n",
      "step 110: loss 1.508\n",
      "step 120: loss 2.563\n",
      "step 130: loss 1.650\n",
      "step 140: loss 1.880\n",
      "step 150: loss 2.550\n",
      "step 160: loss 1.858\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d6ee4217886b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                             \u001b[0msiamese\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0msiamese\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                             siamese.y_: batch_y})\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "\n",
    "\n",
    "# setup siamese network\n",
    "siamese = Siamese()\n",
    "with tf.variable_scope(\"Adam\", reuse=tf.AUTO_REUSE) as scope:\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(siamese.loss)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# if you just want to load a previously trainmodel?\n",
    "load = False\n",
    "model_ckpt = './model.meta'\n",
    "if os.path.isfile(model_ckpt):\n",
    "    input_var = None\n",
    "    while input_var not in ['yes', 'no']:\n",
    "        input_var = input(\"We found model files. Do you want to load it and continue training [yes/no]?\")\n",
    "    if input_var == 'yes':\n",
    "        load = True\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    # start training\n",
    "    if load: saver.restore(sess, './model')\n",
    "\n",
    "    for step in range(20000):\n",
    "        batch_x1, batch_y1 = get_train_mini_batch(np.random.randint(50000))\n",
    "        batch_x2, batch_y2 = get_train_mini_batch(np.random.randint(50000))\n",
    "        min_batch_size = min([batch_x1.shape[0], batch_x2.shape[0]])\n",
    "        batch_x1, batch_y1 = batch_x1[:min_batch_size, :], batch_y1[:min_batch_size]\n",
    "        batch_x2, batch_y2 = batch_x2[:min_batch_size, :], batch_y2[:min_batch_size]\n",
    "        batch_y = (batch_y1 == batch_y2).astype('float')\n",
    "        _, loss_v = sess.run([train_step, siamese.loss], feed_dict={\n",
    "                            siamese.x1: batch_x1,\n",
    "                            siamese.x2: batch_x2,\n",
    "                            siamese.y_: batch_y})\n",
    "\n",
    "        if np.isnan(loss_v):\n",
    "            print('Model diverged with loss = NaN')\n",
    "            quit()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print ('step %d: loss %.3f' % (step, loss_v))\n",
    "\n",
    "        if step % 10 == 0 and step > 0:\n",
    "            saver.save(sess, './model')\n",
    "            x_test, y_test = get_test_mini_batch(step)\n",
    "            embed = siamese.o1.eval({siamese.x1: x_test})\n",
    "            embed.tofile('embed.txt')\n",
    "\n",
    "    # visualize result\n",
    "    x_test, y_test = get_test_mini_batch(1)\n",
    "#     x_test = mnist.test.images.reshape([-1, 28, 28])\n",
    "#     y_test = mnist.test.labels\n",
    "    visualize(embed, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
